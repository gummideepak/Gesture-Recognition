{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ConvColumn\n",
    "model = ConvColumn(27)\n",
    "checkpoint = torch.load('checkpoint.pth.tar')\n",
    "model = torch.nn.DataParallel(model, device_ids=[0,1]).cuda()\n",
    "start_epoch = checkpoint['epoch']\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function export in module torch.onnx:\n",
      "\n",
      "export(model, args, f, export_params=True, verbose=False, training=False)\n",
      "    Export a model into ONNX format.  This exporter runs your model\n",
      "    once in order to get a trace of its execution to be exported; at the\n",
      "    moment, it does not support dynamic models (e.g., RNNs.)\n",
      "    \n",
      "    See also: :ref:`onnx-export`\n",
      "    \n",
      "    Arguments:\n",
      "        model (torch.nn.Module): the model to be exported.\n",
      "        args (tuple of arguments): the inputs to\n",
      "            the model, e.g., such that ``model(*args)`` is a valid\n",
      "            invocation of the model.  Any non-Variable arguments will\n",
      "            be hard-coded into the exported model; any Variable arguments\n",
      "            will become inputs of the exported model, in the order they\n",
      "            occur in args.  If args is a Variable, this is equivalent\n",
      "            to having called it with a 1-ary tuple of that Variable.\n",
      "            (Note: passing keyword arguments to the model is not currently\n",
      "            supported.  Give us a shout if you need it.)\n",
      "        f: a file-like object (has to implement fileno that returns a file descriptor)\n",
      "            or a string containing a file name.  A binary Protobuf will be written\n",
      "            to this file.\n",
      "        export_params (bool, default True): if specified, all parameters will\n",
      "            be exported.  Set this to False if you want to export an untrained model.\n",
      "            In this case, the exported model will first take all of its parameters\n",
      "            as arguments, the ordering as specified by ``model.state_dict().values()``\n",
      "        verbose (bool, default False): if specified, we will print out a debug\n",
      "            description of the trace being exported.\n",
      "        training (bool, default False): export the model in training mode.  At\n",
      "            the moment, ONNX is oriented towards exporting models for inference\n",
      "            only, so you will generally not need to set this to True.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "help(torch.onnx.export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.onnx\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = Variable(torch.randn(1, 3,18,84,84))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hanish\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\nccl.py:27: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ONNX export failed: Couldn't export Python operator Scatter\n\nGraph we tried to export:\ngraph(%1 : Float(1, 3, 18, 84, 84)\n      %2 : Float(64, 3, 3, 3, 3)\n      %3 : Float(64)\n      %4 : Float(64)\n      %5 : Float(64)\n      %6 : Float(64)\n      %7 : Float(64)\n      %8 : Float(128, 64, 3, 3, 3)\n      %9 : Float(128)\n      %10 : Float(128)\n      %11 : Float(128)\n      %12 : Float(128)\n      %13 : Float(128)\n      %14 : Float(256, 128, 3, 3, 3)\n      %15 : Float(256)\n      %16 : Float(256)\n      %17 : Float(256)\n      %18 : Float(256)\n      %19 : Float(256)\n      %20 : Float(256, 256, 3, 3, 3)\n      %21 : Float(256)\n      %22 : Float(256)\n      %23 : Float(256)\n      %24 : Float(256)\n      %25 : Float(256)\n      %26 : Float(512, 12800)\n      %27 : Float(512)\n      %28 : Float(27, 512)\n      %29 : Float(27)) {\n  %31 : Float(1, 3, 18, 84, 84), %32 : Handle = ^Scatter([0, 1], None, 0)(%1), uses = [[%55.i0], []];\n  %34 : Float(64, 3, 3, 3, 3), %35 : Float(64), %36 : Float(64), %37 : Float(64), %38 : Float(128, 64, 3, 3, 3), %39 : Float(128), %40 : Float(128), %41 : Float(128), %42 : Float(256, 128, 3, 3, 3), %43 : Float(256), %44 : Float(256), %45 : Float(256), %46 : Float(256, 256, 3, 3, 3), %47 : Float(256), %48 : Float(256), %49 : Float(256), %50 : Float(512, 12800), %51 : Float(512), %52 : Float(27, 512), %53 : Float(27), %54 : Handle = ^Broadcast((0,))(%2, %3, %4, %5, %8, %9, %10, %11, %14, %15, %16, %17, %20, %21, %22, %23, %26, %27, %28, %29), uses = [[%55.i1], [%57.i1], [%58.i1], [%58.i2], [%62.i1], [%64.i1], [%65.i1], [%65.i2], [%69.i1], [%71.i1], [%72.i1], [%72.i2], [%76.i1], [%78.i1], [%79.i1], [%79.i2], [%86.i1], [%86.i2], [%90.i1], [%90.i2], []];\n  %56 : UNKNOWN_TYPE = Conv[kernel_shape=[3, 3, 3], strides=[1, 1, 1], pads=[1, 1, 1, 1, 1, 1], dilations=[1, 1, 1], group=1](%31, %34), uses = [[%57.i0]];\n  %57 : Float(1, 64, 18, 84, 84) = Add[broadcast=1, axis=1](%56, %35), uses = [%58.i0];\n  %59 : Float(1, 64, 18, 84, 84) = BatchNormalization[is_test=1, epsilon=1e-05, momentum=0.9, consumed_inputs=[0, 0, 0, 1, 1]](%57, %36, %37, %6, %7), uses = [[%60.i0]];\n  %60 : Float(1, 64, 18, 84, 84) = Elu[alpha=1](%59), uses = [%61.i0];\n  %61 : Float(1, 64, 18, 42, 42) = MaxPool[kernel_shape=[1, 2, 2], pads=[0, 0, 0], strides=[1, 2, 2]](%60), uses = [%62.i0];\n  %63 : UNKNOWN_TYPE = Conv[kernel_shape=[3, 3, 3], strides=[1, 1, 1], pads=[1, 1, 1, 1, 1, 1], dilations=[1, 1, 1], group=1](%61, %38), uses = [[%64.i0]];\n  %64 : Float(1, 128, 18, 42, 42) = Add[broadcast=1, axis=1](%63, %39), uses = [%65.i0];\n  %66 : Float(1, 128, 18, 42, 42) = BatchNormalization[is_test=1, epsilon=1e-05, momentum=0.9, consumed_inputs=[0, 0, 0, 1, 1]](%64, %40, %41, %12, %13), uses = [[%67.i0]];\n  %67 : Float(1, 128, 18, 42, 42) = Elu[alpha=1](%66), uses = [%68.i0];\n  %68 : Float(1, 128, 9, 21, 21) = MaxPool[kernel_shape=[2, 2, 2], pads=[0, 0, 0], strides=[2, 2, 2]](%67), uses = [%69.i0];\n  %70 : UNKNOWN_TYPE = Conv[kernel_shape=[3, 3, 3], strides=[1, 1, 1], pads=[1, 1, 1, 1, 1, 1], dilations=[1, 1, 1], group=1](%68, %42), uses = [[%71.i0]];\n  %71 : Float(1, 256, 9, 21, 21) = Add[broadcast=1, axis=1](%70, %43), uses = [%72.i0];\n  %73 : Float(1, 256, 9, 21, 21) = BatchNormalization[is_test=1, epsilon=1e-05, momentum=0.9, consumed_inputs=[0, 0, 0, 1, 1]](%71, %44, %45, %18, %19), uses = [[%74.i0]];\n  %74 : Float(1, 256, 9, 21, 21) = Elu[alpha=1](%73), uses = [%75.i0];\n  %75 : Float(1, 256, 4, 10, 10) = MaxPool[kernel_shape=[2, 2, 2], pads=[0, 0, 0], strides=[2, 2, 2]](%74), uses = [%76.i0];\n  %77 : UNKNOWN_TYPE = Conv[kernel_shape=[3, 3, 3], strides=[1, 1, 1], pads=[1, 1, 1, 1, 1, 1], dilations=[1, 1, 1], group=1](%75, %46), uses = [[%78.i0]];\n  %78 : Float(1, 256, 4, 10, 10) = Add[broadcast=1, axis=1](%77, %47), uses = [%79.i0];\n  %80 : Float(1, 256, 4, 10, 10) = BatchNormalization[is_test=1, epsilon=1e-05, momentum=0.9, consumed_inputs=[0, 0, 0, 1, 1]](%78, %48, %49, %24, %25), uses = [[%81.i0]];\n  %81 : Float(1, 256, 4, 10, 10) = Elu[alpha=1](%80), uses = [%82.i0];\n  %82 : Float(1, 256, 2, 5, 5) = MaxPool[kernel_shape=[2, 2, 2], pads=[0, 0, 0], strides=[2, 2, 2]](%81), uses = [%83.i0];\n  %83 : Float(1, 12800) = Reshape[shape=[1, -1]](%82), uses = [%86.i0];\n  %86 : Float(1, 512) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%83, %50, %51), uses = [%87.i0];\n  %87 : Float(1, 512) = Elu[alpha=1](%86), uses = [%90.i0];\n  %90 : Float(1, 27) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%87, %52, %53), uses = [%91.i0];\n  %92 : Float(1, 27), %93 : Handle = ^Gather(0, 0)(%90), uses = [[%0.i0], []];\n  return (%92);\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-74e0465faaea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"alexnet.onnx\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexport_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\__init__.py\u001b[0m in \u001b[0;36m_export\u001b[1;34m(model, args, f, export_params, verbose, training)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m# NB: OrderedDict values is not actually a list, but trace.export is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# not duck-typed and expects an actual list.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mproto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_onnx_opset_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mproto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_onnx_opset_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: ONNX export failed: Couldn't export Python operator Scatter\n\nGraph we tried to export:\ngraph(%1 : Float(1, 3, 18, 84, 84)\n      %2 : Float(64, 3, 3, 3, 3)\n      %3 : Float(64)\n      %4 : Float(64)\n      %5 : Float(64)\n      %6 : Float(64)\n      %7 : Float(64)\n      %8 : Float(128, 64, 3, 3, 3)\n      %9 : Float(128)\n      %10 : Float(128)\n      %11 : Float(128)\n      %12 : Float(128)\n      %13 : Float(128)\n      %14 : Float(256, 128, 3, 3, 3)\n      %15 : Float(256)\n      %16 : Float(256)\n      %17 : Float(256)\n      %18 : Float(256)\n      %19 : Float(256)\n      %20 : Float(256, 256, 3, 3, 3)\n      %21 : Float(256)\n      %22 : Float(256)\n      %23 : Float(256)\n      %24 : Float(256)\n      %25 : Float(256)\n      %26 : Float(512, 12800)\n      %27 : Float(512)\n      %28 : Float(27, 512)\n      %29 : Float(27)) {\n  %31 : Float(1, 3, 18, 84, 84), %32 : Handle = ^Scatter([0, 1], None, 0)(%1), uses = [[%55.i0], []];\n  %34 : Float(64, 3, 3, 3, 3), %35 : Float(64), %36 : Float(64), %37 : Float(64), %38 : Float(128, 64, 3, 3, 3), %39 : Float(128), %40 : Float(128), %41 : Float(128), %42 : Float(256, 128, 3, 3, 3), %43 : Float(256), %44 : Float(256), %45 : Float(256), %46 : Float(256, 256, 3, 3, 3), %47 : Float(256), %48 : Float(256), %49 : Float(256), %50 : Float(512, 12800), %51 : Float(512), %52 : Float(27, 512), %53 : Float(27), %54 : Handle = ^Broadcast((0,))(%2, %3, %4, %5, %8, %9, %10, %11, %14, %15, %16, %17, %20, %21, %22, %23, %26, %27, %28, %29), uses = [[%55.i1], [%57.i1], [%58.i1], [%58.i2], [%62.i1], [%64.i1], [%65.i1], [%65.i2], [%69.i1], [%71.i1], [%72.i1], [%72.i2], [%76.i1], [%78.i1], [%79.i1], [%79.i2], [%86.i1], [%86.i2], [%90.i1], [%90.i2], []];\n  %56 : UNKNOWN_TYPE = Conv[kernel_shape=[3, 3, 3], strides=[1, 1, 1], pads=[1, 1, 1, 1, 1, 1], dilations=[1, 1, 1], group=1](%31, %34), uses = [[%57.i0]];\n  %57 : Float(1, 64, 18, 84, 84) = Add[broadcast=1, axis=1](%56, %35), uses = [%58.i0];\n  %59 : Float(1, 64, 18, 84, 84) = BatchNormalization[is_test=1, epsilon=1e-05, momentum=0.9, consumed_inputs=[0, 0, 0, 1, 1]](%57, %36, %37, %6, %7), uses = [[%60.i0]];\n  %60 : Float(1, 64, 18, 84, 84) = Elu[alpha=1](%59), uses = [%61.i0];\n  %61 : Float(1, 64, 18, 42, 42) = MaxPool[kernel_shape=[1, 2, 2], pads=[0, 0, 0], strides=[1, 2, 2]](%60), uses = [%62.i0];\n  %63 : UNKNOWN_TYPE = Conv[kernel_shape=[3, 3, 3], strides=[1, 1, 1], pads=[1, 1, 1, 1, 1, 1], dilations=[1, 1, 1], group=1](%61, %38), uses = [[%64.i0]];\n  %64 : Float(1, 128, 18, 42, 42) = Add[broadcast=1, axis=1](%63, %39), uses = [%65.i0];\n  %66 : Float(1, 128, 18, 42, 42) = BatchNormalization[is_test=1, epsilon=1e-05, momentum=0.9, consumed_inputs=[0, 0, 0, 1, 1]](%64, %40, %41, %12, %13), uses = [[%67.i0]];\n  %67 : Float(1, 128, 18, 42, 42) = Elu[alpha=1](%66), uses = [%68.i0];\n  %68 : Float(1, 128, 9, 21, 21) = MaxPool[kernel_shape=[2, 2, 2], pads=[0, 0, 0], strides=[2, 2, 2]](%67), uses = [%69.i0];\n  %70 : UNKNOWN_TYPE = Conv[kernel_shape=[3, 3, 3], strides=[1, 1, 1], pads=[1, 1, 1, 1, 1, 1], dilations=[1, 1, 1], group=1](%68, %42), uses = [[%71.i0]];\n  %71 : Float(1, 256, 9, 21, 21) = Add[broadcast=1, axis=1](%70, %43), uses = [%72.i0];\n  %73 : Float(1, 256, 9, 21, 21) = BatchNormalization[is_test=1, epsilon=1e-05, momentum=0.9, consumed_inputs=[0, 0, 0, 1, 1]](%71, %44, %45, %18, %19), uses = [[%74.i0]];\n  %74 : Float(1, 256, 9, 21, 21) = Elu[alpha=1](%73), uses = [%75.i0];\n  %75 : Float(1, 256, 4, 10, 10) = MaxPool[kernel_shape=[2, 2, 2], pads=[0, 0, 0], strides=[2, 2, 2]](%74), uses = [%76.i0];\n  %77 : UNKNOWN_TYPE = Conv[kernel_shape=[3, 3, 3], strides=[1, 1, 1], pads=[1, 1, 1, 1, 1, 1], dilations=[1, 1, 1], group=1](%75, %46), uses = [[%78.i0]];\n  %78 : Float(1, 256, 4, 10, 10) = Add[broadcast=1, axis=1](%77, %47), uses = [%79.i0];\n  %80 : Float(1, 256, 4, 10, 10) = BatchNormalization[is_test=1, epsilon=1e-05, momentum=0.9, consumed_inputs=[0, 0, 0, 1, 1]](%78, %48, %49, %24, %25), uses = [[%81.i0]];\n  %81 : Float(1, 256, 4, 10, 10) = Elu[alpha=1](%80), uses = [%82.i0];\n  %82 : Float(1, 256, 2, 5, 5) = MaxPool[kernel_shape=[2, 2, 2], pads=[0, 0, 0], strides=[2, 2, 2]](%81), uses = [%83.i0];\n  %83 : Float(1, 12800) = Reshape[shape=[1, -1]](%82), uses = [%86.i0];\n  %86 : Float(1, 512) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%83, %50, %51), uses = [%87.i0];\n  %87 : Float(1, 512) = Elu[alpha=1](%86), uses = [%90.i0];\n  %90 : Float(1, 27) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%87, %52, %53), uses = [%91.i0];\n  %92 : Float(1, 27), %93 : Handle = ^Gather(0, 0)(%90), uses = [[%0.i0], []];\n  return (%92);\n}\n"
     ]
    }
   ],
   "source": [
    "torch_out = torch.onnx._export(model, dummy_input, \"alexnet.onnx\",export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
